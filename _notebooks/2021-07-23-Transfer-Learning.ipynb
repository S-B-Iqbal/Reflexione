{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet(TL).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14c007cc25d740d48eea05d684ee9fc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aa21549d173e4643bd7430f35b591383",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_717fe168bc4a48cda0ad99de053fd0e9",
              "IPY_MODEL_ea7e82c3fee04415b19e7bbd9d254f8b"
            ]
          }
        },
        "aa21549d173e4643bd7430f35b591383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "717fe168bc4a48cda0ad99de053fd0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d26c68ce34e444d89283759f60743678",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244408911,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244408911,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fa7b1492e674475ca52f9c46028e22bc"
          }
        },
        "ea7e82c3fee04415b19e7bbd9d254f8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9a0c0892f4e448f8bf0087dfa636b6b9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 233M/233M [01:32&lt;00:00, 2.63MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46ecf522029a41e3980936b3a13e3b1d"
          }
        },
        "d26c68ce34e444d89283759f60743678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fa7b1492e674475ca52f9c46028e22bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a0c0892f4e448f8bf0087dfa636b6b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46ecf522029a41e3980936b3a13e3b1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql-5AztC2Zka"
      },
      "source": [
        "# The Fish and the Trasnferred (Alex)Net\n",
        "> \"Implementation of Transfer Learning on a custom dataset\"\n",
        "\n",
        "\n",
        "- toc: true\n",
        "- branch: master\n",
        "- badges: true\n",
        "- comments: false\n",
        "- categories: [Transfer Learning,AlexNet, PyTorch, Image Classification]\n",
        "- image: images/tl.jpeg\n",
        "- hide: false\n",
        "- search_exclude: true\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jxf1oguqBJ1"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "- At times we have felt that learning to perform one task makes it easier to learn a similar task. For instance, I have played Badminton all my life(or maybe teenage years of it) and when I tried to play Tennis it was quite easy to learn the nuances of the game. Similarly, In Deep Learning, we can use _Transfer Learning_ i.e., use a PreTrained model on a similar dataset or problem for a custom dataset which is usually small in size.\n",
        "\n",
        "- In the previous [Blog](URL), we applied AlexNet from scratch and did not observe really good results on the Custom Dataset. \n",
        "\n",
        "- But, here we use a PreTrained AlexNet provided by PyTorch and observe changes in Training Time and Accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCUrLk-Emi5E"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F14xrAo6mLja"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "from PIL import Image\n",
        "\n",
        "import time\n",
        "import seaborn as sns\n",
        "import glob\n",
        "from pathlib import Path\n",
        "torch.manual_seed(1)\n",
        "np.random.seed(1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whoCNentmnH7"
      },
      "source": [
        "data_path = Path.cwd()/'Fish_Dataset/Fish_Dataset'\n",
        "\n",
        "# Path for all the files in a 'png' format.\n",
        "image_path = list(data_path.glob('**/*.png')) \n",
        "\n",
        "# Separate Segmented from Non-Segmented Images\n",
        "\n",
        "non_segmented_images = [img for img in image_path if 'GT' not in str(img)]\n",
        "labels_non_segment = [img.parts[-3] for img in non_segmented_images]\n",
        "\n",
        "segmented_images = [img for img in image_path if 'GT' in str(img)]\n",
        "lables_segment = [img.parts[-3] for img in segmented_images]\n",
        "\n",
        "classes = list(set(lables_segment))\n",
        "\n",
        "# Convert String Labels to int\n",
        "\n",
        "int_classes = {fish:i for i,fish in enumerate(classes)}\n",
        "\n",
        "lables = [int_classes[lable] for lable in labels_non_segment]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQr1wDlcmnEj"
      },
      "source": [
        "image_data = pd.DataFrame({'Path': non_segmented_images,\\\n",
        "              'labels': lables})"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5nP_NXpmnBJ"
      },
      "source": [
        "class FishDataset(Dataset):\n",
        "  \"\"\"Class for loading an Image.\"\"\"\n",
        "  def __init__(self, images, labels, transform = None):\n",
        "    self.images = images\n",
        "    self.labels = labels\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = Image.open(self.images.iloc[idx])\n",
        "\n",
        "    if self.transform:\n",
        "      img = self.transform(img)\n",
        "    label = self.labels.iloc[idx]\n",
        "    return img, label"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eazdBFeTmm-f"
      },
      "source": [
        "train,test, train_labels, test_labels = train_test_split(image_data.Path, image_data.labels, test_size=0.2, shuffle=True)\n",
        "\n",
        "train,val, train_labels, val_labels = train_test_split(train, train_labels, test_size=0.2, shuffle=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMPrqUGcmm4a"
      },
      "source": [
        "def get_loaders(train, train_labels, val, val_labels,test, test_labels, batch_size, num_workers, train_transform, test_transform):\n",
        "  \"\"\"\n",
        "  Returns the Train, Validation and Test DataLoaders.\n",
        "  \"\"\"\n",
        "\n",
        "  train_ds = FishDataset(images = train, labels = train_labels, transform = train_transform)\n",
        "  val_ds = FishDataset(images = val, labels = val_labels, transform = test_transforms)\n",
        "  test_ds = FishDataset(images = test, labels = test_labels, transform = test_transforms)\n",
        "\n",
        "  train_loader = DataLoader(train_ds, batch_size=batch_size,num_workers=num_workers,\n",
        "                            shuffle= True)\n",
        "  val_loader = DataLoader(val_ds, batch_size=batch_size,num_workers=num_workers,\n",
        "                            shuffle= False)\n",
        "  test_loader = DataLoader(test_ds, batch_size=batch_size,num_workers=num_workers,\n",
        "                          shuffle= False)\n",
        "  return train_loader, val_loader, test_loader\n",
        "\n",
        "def set_all_seeds(seed):\n",
        "  os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def compute_accuracy(model, data_loader, device):\n",
        "  model.eval\n",
        "  with torch.no_grad():\n",
        "    correct_pred, num_examples = 0, 0\n",
        "\n",
        "    for i, (features, targets) in enumerate(data_loader):\n",
        "      features = features.to(device)\n",
        "      targets = targets.float().to(device)\n",
        "\n",
        "      logits = model(features)\n",
        "      _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "      num_examples += targets.size(0)\n",
        "      correct_pred += (predicted_labels == targets).sum()\n",
        "  return correct_pred.float()/num_examples * 100\n",
        "\n",
        "\n",
        "class UnNormalize(object):\n",
        "  def __init__(self, mean, std):\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "  def __call__(self, tensor):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    ------------\n",
        "    tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        \n",
        "    Returns:\n",
        "    ------------\n",
        "    Tensor: Normalized image.\n",
        "    \"\"\"\n",
        "    for t, m, s in zip(tensor, self.mean, self.std):\n",
        "      t.mul_(s).add_(m)\n",
        "    return tensor"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8APe6hAmmrw"
      },
      "source": [
        "##########################\n",
        "### FISH DATASET\n",
        "##########################\n",
        "\n",
        "train_transform = transforms.Compose([transforms.Resize((64,64)),\n",
        "                                      transforms.ColorJitter(brightness=0.5, contrast=0,saturation=0, hue=0),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "                                      ])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize((64,64)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENQbYrBCuisD"
      },
      "source": [
        "## Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUEDZgY36vwg"
      },
      "source": [
        "### Step-1: PreTrain a Neural Network\n",
        "\n",
        "- We use a Pre-trained AlexNet on __ImageNet__ dataset as the _source model_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596,
          "referenced_widgets": [
            "14c007cc25d740d48eea05d684ee9fc3",
            "aa21549d173e4643bd7430f35b591383",
            "717fe168bc4a48cda0ad99de053fd0e9",
            "ea7e82c3fee04415b19e7bbd9d254f8b",
            "d26c68ce34e444d89283759f60743678",
            "fa7b1492e674475ca52f9c46028e22bc",
            "9a0c0892f4e448f8bf0087dfa636b6b9",
            "46ecf522029a41e3980936b3a13e3b1d"
          ]
        },
        "id": "eqGgpL_ImxKe",
        "outputId": "22c323a0-f58a-4a7d-c45e-2284b674dad8"
      },
      "source": [
        "alexnet = models.alexnet(pretrained=True)\n",
        "alexnet"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14c007cc25d740d48eea05d684ee9fc3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244408911.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (7): ReLU(inplace=True)\n",
              "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnYKrpUGnc0f"
      },
      "source": [
        "### Step-2: Create a _Target Model_\n",
        "\n",
        "- Except the **_classifier_** layer, we copy all the model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpOWz8YrncYW"
      },
      "source": [
        "# Freezing all the layers\n",
        "for param in alexnet.parameters():\n",
        "  param.requires_grad = False"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-xASEO5nqvp"
      },
      "source": [
        "#### Step-3: Fine-Tuning the _Target Model_\n",
        "\n",
        "1. We fine-tune `classifier` layer:\n",
        "2. We add the Output layer to the final layer of Multilayer Perceptron in `classifier` layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu__hufAmxG-"
      },
      "source": [
        "alexnet.classifier[1].requires_grad = True\n",
        "alexnet.classifier[4].requires_grad = True\n",
        "alexnet.classifier[6].requires_grad = True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPRqQ-ZPmxEZ"
      },
      "source": [
        "# We have 9 Fish classes\n",
        "alexnet.classifier[6] = nn.Linear(in_features=4096, out_features=9, bias=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh6FtCI9oriu"
      },
      "source": [
        "### Step-4: Train target model on _Target Dataset_\n",
        "\n",
        "1. We Train the output layer i.e., `classifier` from scratch.\n",
        "2. We update the parameters of all the input layers except the output layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-lAxbvlmxBh"
      },
      "source": [
        "##########################\n",
        "### SETTINGS\n",
        "##########################\n",
        "\n",
        "RANDOM_SEED = 123\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 10\n",
        "WORKERS = 2\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KloHu1grmw-k"
      },
      "source": [
        "set_all_seeds(RANDOM_SEED)\n",
        "\n",
        "train_loader, val_loader, test_loader = get_loaders(train,train_labels,val, val_labels, test,test_labels, BATCH_SIZE,WORKERS,\n",
        "                                                    train_transform, test_transforms)\n",
        "\n",
        "model = alexnet.to(DEVICE)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5gbpYexmw7z"
      },
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, lr=0.1)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       factor=0.1,\n",
        "                                                       mode='max',\n",
        "                                                       verbose=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSvx-Dr3o7nd",
        "outputId": "b6b144d3-9ca8-4a89-fc2d-b5447127da97"
      },
      "source": [
        "logging_interval = 50\n",
        "scheduler_on='minibatch_loss'\n",
        "start_time = time.time()\n",
        "\n",
        "minibatch_loss_list, train_acc_list, valid_acc_list = [],[],[]\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  # Start Training\n",
        "  model.train()\n",
        "  for batch_idx, (features, target) in enumerate(train_loader):\n",
        "    features = features.to(DEVICE)\n",
        "    targets = target.to(DEVICE)\n",
        "    # Forward and BackPropagation\n",
        "    logits = model(features)\n",
        "    loss = F.cross_entropy(logits, targets)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update Model Parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    ## LOGGING\n",
        "    minibatch_loss_list.append(loss.item())\n",
        "    if not batch_idx % logging_interval:\n",
        "      print(f\"Epoch = {epoch+1:03d}/{NUM_EPOCHS:03d}\"\n",
        "      f\"| Batch {batch_idx:04d}/{len(train_loader):04d}\"\n",
        "      f\"| Loss: {loss:.4f}\")\n",
        "    \n",
        "  ## Validation\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    train_acc = compute_accuracy(model, train_loader, DEVICE)\n",
        "    valid_acc = compute_accuracy(model, val_loader, DEVICE)\n",
        "    print(f'Epoch: {epoch+1}/{NUM_EPOCHS:03d} '\n",
        "    f'| Train: {train_acc :.2f}% '\n",
        "    f'| Validation: {valid_acc :.2f}%')\n",
        "    train_acc_list.append(train_acc)\n",
        "    valid_acc_list.append(valid_acc)\n",
        "    \n",
        "  elapsed = (time.time() - start_time)/60\n",
        "  print(f'Time elapsed: {elapsed:.2f} min')\n",
        "\n",
        "  if scheduler is not None:\n",
        "    if scheduler_on == \"valid_acc\":\n",
        "      scheduler.step(valid_acc_list[-1])\n",
        "    if scheduler_on == 'minibatch_loss':\n",
        "      scheduler.step(minibatch_loss_list[-1])\n",
        "    else:\n",
        "      raise ValueError(\"Invalid `scheduler_on` choice\")\n",
        "\n",
        "total_elapsed = (time.time() - start_time)/60\n",
        "print(f'Total Training Time: {total_elapsed:.2f} min')\n",
        "\n",
        "# Compute Test Accuracy\n",
        "test_acc = compute_accuracy(model, test_loader, device=DEVICE)\n",
        "\n",
        "print(f\"Test accuracy: {test_acc:0.3f}\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch = 001/010| Batch 0000/0023| Loss: 163.3353\n",
            "Epoch: 1/010 | Train: 88.77% | Validation: 88.06%\n",
            "Time elapsed: 1.91 min\n",
            "Epoch = 002/010| Batch 0000/0023| Loss: 72.6810\n",
            "Epoch: 2/010 | Train: 89.51% | Validation: 88.89%\n",
            "Time elapsed: 3.82 min\n",
            "Epoch = 003/010| Batch 0000/0023| Loss: 63.1871\n",
            "Epoch: 3/010 | Train: 90.26% | Validation: 89.31%\n",
            "Time elapsed: 5.73 min\n",
            "Epoch = 004/010| Batch 0000/0023| Loss: 62.3928\n",
            "Epoch: 4/010 | Train: 91.15% | Validation: 89.86%\n",
            "Time elapsed: 7.65 min\n",
            "Epoch = 005/010| Batch 0000/0023| Loss: 47.7385\n",
            "Epoch: 5/010 | Train: 92.31% | Validation: 90.56%\n",
            "Time elapsed: 9.56 min\n",
            "Epoch = 006/010| Batch 0000/0023| Loss: 62.1415\n",
            "Epoch: 6/010 | Train: 92.20% | Validation: 90.35%\n",
            "Time elapsed: 11.48 min\n",
            "Epoch = 007/010| Batch 0000/0023| Loss: 46.1223\n",
            "Epoch: 7/010 | Train: 92.71% | Validation: 91.60%\n",
            "Time elapsed: 13.40 min\n",
            "Epoch = 008/010| Batch 0000/0023| Loss: 44.8405\n",
            "Epoch: 8/010 | Train: 92.74% | Validation: 90.90%\n",
            "Time elapsed: 15.32 min\n",
            "Epoch = 009/010| Batch 0000/0023| Loss: 37.8981\n",
            "Epoch: 9/010 | Train: 93.18% | Validation: 91.46%\n",
            "Time elapsed: 17.24 min\n",
            "Epoch = 010/010| Batch 0000/0023| Loss: 29.6452\n",
            "Epoch: 10/010 | Train: 93.77% | Validation: 92.22%\n",
            "Time elapsed: 19.16 min\n",
            "Total Training Time: 19.16 min\n",
            "Test accuracy: 91.722\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIUce5aXuOqo"
      },
      "source": [
        "### Comments\n",
        "- Training Time was reduced by 11 mins!\n",
        "- Test Accuracy within 10 epochs incresed to **91.722%** from 11%. So, Fine-Tuning did help in increasing AlexNet's generalizanility on the source dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ODzWHdsw9J5"
      },
      "source": [
        "### References\n",
        "\n",
        "1. Code:\n",
        "----\n",
        "[Sebastian Raschka's](https://nbviewer.jupyter.org/github/rasbt/deeplearning-models/blob/master/pytorch_ipynb/transfer/transferlearning-vgg16-cifar10-1.ipynb) implementation on CIFAR-10 is a great start\n",
        "\n",
        "2. Theory:\n",
        "----\n",
        "[D2L](http://d2l.ai/chapter_computer-vision/fine-tuning.html#)'s explanation is concise and simple for initial reader's."
      ]
    }
  ]
}